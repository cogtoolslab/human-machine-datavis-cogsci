{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9196c789-b3d4-46f4-9089-126f0e6ceffb",
   "metadata": {},
   "source": [
    "## Processed responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e041dd-d601-4850-a6ae-9fc0fd6041a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import SentenceTransformer. Please install the library using 'pip install sentence-transformers'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tacl_analysis.evaluation_metrics import EvaluationMetrics\n",
    "evaluation_metric = EvaluationMetrics()\n",
    "from numpy.random import Generator, PCG64\n",
    "from joblib import Parallel, delayed\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "fd15fac6-1e17-4e0c-b69a-fe69519b0313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d1600c5c-00bc-4475-8b15-fbf19038a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggr_questions = pd.read_csv(\"https://data-visualization-benchmark.s3.us-west-2.amazonaws.com/ggr/questions.csv\")\n",
    "vlat_questions = pd.read_csv(\"https://data-visualization-benchmark.s3.us-west-2.amazonaws.com/vlat/questions.csv\")\n",
    "holf_questions = pd.read_csv(\"https://data-visualization-benchmark.s3.us-west-2.amazonaws.com/holf/questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "136990fa-49d9-40e1-8003-750b7f60f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggr = pd.read_csv(\"https://data-visualization-benchmark.s3.us-west-2.amazonaws.com/ggr/responses/indist_instructions_question/p04/t1/processed_extracted_responses.csv\")\n",
    "holf = pd.read_csv(\"https://data-visualization-benchmark.s3.us-west-2.amazonaws.com/holf/responses/indist_instructions_question/p04/t1/processed_extracted_responses.csv\")\n",
    "vlat = pd.read_csv('https://data-visualization-benchmark.s3.us-west-2.amazonaws.com/vlat/responses/indist_instructions_question/p04/t1/processed_extracted_responses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "c6710c81-207d-433f-8c28-7db8cc8f97c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggr_human = pd.read_csv(\"https://data-visualization-benchmark.s3.us-west-2.amazonaws.com/ggr/responses/indist_instructions_question/p04/t1/model_responses.csv\")\n",
    "ggr_human = ggr_human[(ggr_human[\"agentType\"] == \"Human/Math-2-1\") | \n",
    "                        (ggr_human[\"agentType\"] == \"Human/Math-3\") | \n",
    "                        (ggr_human[\"agentType\"] == \"Human\")]\n",
    "vlat_human = pd.read_csv(\"https://data-visualization-benchmark.s3.us-west-2.amazonaws.com/vlat/responses/indist_instructions_question/p04/t1/model_responses.csv\")\n",
    "vlat_human = vlat_human[(vlat_human[\"agentType\"] == \"Human/Math-2-1\") | \n",
    "                        (vlat_human[\"agentType\"] == \"Human/Math-3\") | \n",
    "                        (vlat_human[\"agentType\"] == \"Human\")]\n",
    "holf_human = pd.read_csv(\"https://data-visualization-benchmark.s3.us-west-2.amazonaws.com/holf/responses/indist_instructions_question/p04/t1/model_responses.csv\")\n",
    "holf_human = holf_human[(holf_human[\"agentType\"] == \"Human/Math-2-1\") | \n",
    "                        (holf_human[\"agentType\"] == \"Human/Math-3\") | \n",
    "                        (holf_human[\"agentType\"] == \"Human\")]\n",
    "\n",
    "ggr = pd.concat([ggr, ggr_human])\n",
    "vlat = pd.concat([vlat, vlat_human])\n",
    "holf = pd.concat([holf, holf_human])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "4bf2ef46-e8f8-462a-bae4-6f3a1f676051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holf.drop(columns=[\"min_label\", \"max_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "2a0871c3-acae-4458-a932-52a6a7706134",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggr = ggr[ggr[\"testType\"] == \"ggr\"]\n",
    "vlat = vlat[vlat[\"testType\"] == \"vlat\"]\n",
    "holf = holf[holf[\"testType\"] == \"holf\"]\n",
    "\n",
    "ggr[\"correct_answer\"] = ggr[\"correctAnswer\"]\n",
    "ggr[\"a_in_b\"] = ggr.apply(\n",
    "    lambda r: int(evaluation_metric.a_in_b(r['correct_answer'], r['agent_response'])), axis=1\n",
    ")\n",
    "\n",
    "vlat[\"correct_answer\"] = vlat[\"correctAnswer\"]\n",
    "vlat[\"a_in_b\"] = vlat.apply(\n",
    "    lambda r: int(evaluation_metric.a_in_b(r['correct_answer'], r['agent_response'])), axis=1\n",
    ")\n",
    "\n",
    "holf = holf.drop(columns=[\"min_label\", \"max_label\"])\n",
    "holf[\"correct_answer\"] = holf[\"correctAnswer\"]\n",
    "holf[\"agent_response\"] = holf[\"agent_response\"].astype(float)\n",
    "holf[\"error\"] = holf.apply(\n",
    "    lambda r: evaluation_metric.get_absolute_error(r['agent_response'], r['correct_answer']), axis=1\n",
    ")\n",
    "holf = holf.dropna(subset=[\"error\"])\n",
    "merged_response = holf_questions[[\"question\", \"image_file\", \"min_label\", \"max_label\"]]\n",
    "holf = holf.merge(merged_response, on=[\"question\", \"image_file\"])\n",
    "\n",
    "holf[\"minmax_axis_normalized_error\"] = holf.apply(\n",
    "    lambda r: evaluation_metric.minmax_normalized_error(r['error'], r['min_label'], r['max_label']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "f590e0cf-2de3-42de-89f4-128f0fde6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(\n",
    "        raw_data, \n",
    "        n_iterations=1000,\n",
    "        statistic=np.mean,\n",
    "        units_of_measure=\"a_in_b\"):\n",
    "    data = raw_data.copy()\n",
    "    data[\"question_image\"] = data[\"question\"] + \" & \" + data[\"image_file\"]\n",
    "    rng = Generator(PCG64())\n",
    "    questions = list(data[\"question_image\"].unique())\n",
    "    n_size = len(questions)\n",
    "    df = data.copy()\n",
    "\n",
    "    # sample within the data\n",
    "    df = df.sample(frac=1, replace=True, random_state=1)\n",
    "\n",
    "    def bootstrap_iteration(data, chosen_qs):\n",
    "        filter_df = data[data[\"question_image\"].isin(chosen_qs)] # Filter based on chosen questions\n",
    "        bs_mean = statistic(filter_df[units_of_measure]) #.mean() # Calculate mean of the filtered data\n",
    "        return bs_mean\n",
    "    means = Parallel(n_jobs=-1)(\n",
    "        delayed(bootstrap_iteration)(df, rng.choice(questions, n_size,  replace=True)) for _ in range(n_iterations)\n",
    "    )\n",
    "    \n",
    "    # 95% confidence interval\n",
    "    lower = np.percentile(means, 2.5)\n",
    "    upper = np.percentile(means, 97.5)\n",
    "    \n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "def create_confidence_interval_df(data, statistic=np.mean, units_of_measure=\"a_in_b\"):\n",
    "    data_list = []\n",
    "    # num_questions = len(self.questions[[\"question\", \"image_file\"]])\n",
    "\n",
    "    for agent in data[\"agentType\"].unique():\n",
    "        agent_res = data[data[\"agentType\"] == agent]\n",
    "\n",
    "        lower, upper = bootstrap_ci(agent_res, statistic=statistic, units_of_measure=units_of_measure)\n",
    "\n",
    "        data_list.append({\n",
    "            \"agentType\": agent,\n",
    "            \"ci_upper\": upper, \n",
    "            \"ci_lower\": lower,\n",
    "            # \"value_count\": len(agent_res[['question', 'image_file']].value_counts()) / num_questions,\n",
    "            \"mean\": statistic(agent_res[units_of_measure])\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "67c96284-6101-4934-8bcf-18fd06737b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(in_df,\n",
    "        statistic=np.mean,\n",
    "        units_of_measure=\"a_in_b\"\n",
    "        ):\n",
    "    agent_map = {\n",
    "        \"llava-hf/llava-1.5-7b-hf\": \"model\",\n",
    "        'Salesforce/blip2-flan-t5-xl': \"model\",\n",
    "        'Salesforce/blip2-flan-t5-xxl': \"model\",\n",
    "        'GPT-4V': \"GPT-4V\",\n",
    "    }\n",
    "    \n",
    "    df = in_df.replace(agent_map)\n",
    "    return create_confidence_interval_df(\n",
    "        df[df[\"agentType\"] == \"model\"], \n",
    "        statistic=statistic,\n",
    "        units_of_measure=units_of_measure\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "d679d378-39a6-461d-8d5b-2858d5e3e416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agentType</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model</td>\n",
       "      <td>0.07489</td>\n",
       "      <td>0.013495</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  agentType  ci_upper  ci_lower      mean\n",
       "0     model   0.07489  0.013495  0.051282"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(ggr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ada750c0-69d0-4610-91b8-1235c1075ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agentType</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model</td>\n",
       "      <td>0.397253</td>\n",
       "      <td>0.255589</td>\n",
       "      <td>0.320126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  agentType  ci_upper  ci_lower      mean\n",
       "0     model  0.397253  0.255589  0.320126"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(vlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "510eb610-86f2-4ab9-a7b1-c4e269ebbb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agentType</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model</td>\n",
       "      <td>0.330317</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  agentType  ci_upper  ci_lower  mean\n",
       "0     model  0.330317     0.296   0.3"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(holf, statistic=np.median, units_of_measure=\"minmax_axis_normalized_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9452d3-86fa-42b2-b480-79254284ff80",
   "metadata": {},
   "source": [
    "### ACC difference of means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "ece240a3-fc56-47c3-be7d-fec07bcee145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dom_bootstrap_ci(\n",
    "    raw_data,\n",
    "    col1,\n",
    "    col2,\n",
    "    n_iterations=1000,\n",
    "    statistic=np.mean,\n",
    "    units_of_measure=\"a_in_b\",\n",
    "):\n",
    "    \n",
    "    data = raw_data.copy()\n",
    "    data[\"question_image\"] = data[\"question\"] + \" & \" + data[\"image_file\"]\n",
    "    rng = Generator(PCG64())\n",
    "    questions = list(data[\"question_image\"].unique())\n",
    "    n_size = len(questions)\n",
    "    df = data.copy()\n",
    "\n",
    "    # sample within the data\n",
    "    df = df.sample(frac=1, replace=True, random_state=1)\n",
    "\n",
    "    def bootstrap_iteration(data, chosen_qs):\n",
    "        filter_df = data[data[\"question_image\"].isin(chosen_qs)] # Filter based on chosen questions\n",
    "        col1_res = filter_df[(filter_df[\"agentType\"] == col1)][units_of_measure]\n",
    "        col2_res = filter_df[(filter_df[\"agentType\"] == col2)][units_of_measure]\n",
    "        \n",
    "        bs_mean = statistic(col1_res) - statistic(col2_res)\n",
    "        return bs_mean\n",
    "        \n",
    "    means = Parallel(n_jobs=-1)(\n",
    "        delayed(bootstrap_iteration)(df, rng.choice(questions, n_size,  replace=True)) for _ in range(n_iterations)\n",
    "    )\n",
    "    \n",
    "    # 95% confidence interval\n",
    "    lower = np.percentile(means, 2.5)\n",
    "    upper = np.percentile(means, 97.5)\n",
    "    \n",
    "    return lower, upper\n",
    "\n",
    "def create_confidence_interval_dom_df(data, col1, col2, statistic=np.mean, units_of_measure=\"a_in_b\"):\n",
    "    data_list = []\n",
    "    lower, upper = dom_bootstrap_ci(\n",
    "        data, \n",
    "        col1,\n",
    "        col2,\n",
    "        statistic=statistic, \n",
    "        units_of_measure=units_of_measure\n",
    "    )\n",
    "\n",
    "    data_list.append({\n",
    "        # \"agentType\": agent,\n",
    "        \"ci_upper\": upper, \n",
    "        \"ci_lower\": lower,\n",
    "        \"mean\": (\n",
    "            statistic(data[data[\"agentType\"] == col1][units_of_measure]) - \n",
    "            statistic(data[data[\"agentType\"] == col2][units_of_measure]))\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "f76d9905-3707-4e88-baed-50f4ccb74d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.602054</td>\n",
       "      <td>0.260507</td>\n",
       "      <td>0.439888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ci_upper  ci_lower      mean\n",
       "0  0.602054  0.260507  0.439888"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_confidence_interval_dom_df(ggr, \"Human/Math-2-1\", \"GPT-4V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "1fc82a81-3165-4121-be82-8399aadae341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.272629</td>\n",
       "      <td>0.081865</td>\n",
       "      <td>0.133108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ci_upper  ci_lower      mean\n",
       "0  0.272629  0.081865  0.133108"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_confidence_interval_dom_df(vlat, \"Human/Math-2-1\", \"GPT-4V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "88c3afa7-f858-44a7-9c78-3cee4f284543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.033715</td>\n",
       "      <td>-0.056118</td>\n",
       "      <td>-0.040556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ci_upper  ci_lower      mean\n",
       "0 -0.033715 -0.056118 -0.040556"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_confidence_interval_dom_df(holf, \"Human/Math-2-1\", \"GPT-4V\", \n",
    "                                  statistic=np.median, units_of_measure=\"minmax_axis_normalized_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "329fd0a8-8f29-4fc4-b208-4b44135138ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agentType\n",
       "GPT-4V                          0.620424\n",
       "Salesforce/blip2-flan-t5-xl     0.305882\n",
       "Salesforce/blip2-flan-t5-xxl    0.297456\n",
       "llava-hf/llava-1.5-7b-hf        0.379245\n",
       "Name: a_in_b, dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlat.dropna(subset=[\"agent_response\"]).groupby(\"agentType\")['a_in_b'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "77eb0a61-e171-4192-a8dd-372be290d9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f856bb2c-803b-4d7a-b931-bed96cdc4013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agentType\n",
       "GPT-4V                          0.330357\n",
       "Salesforce/blip2-flan-t5-xl     0.019802\n",
       "Salesforce/blip2-flan-t5-xxl    0.025862\n",
       "llava-hf/llava-1.5-7b-hf        0.500000\n",
       "Name: answer_in_response, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlat.dropna(subset=[\"agent_response\"]).groupby([\"agentType\"]).apply(lambda g : len(g) / 45).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "15059772-60e7-4a02-9a58-214f83f29997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "380318f8-b68d-49ed-a0f0-c70d83ee5320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4c279d0-b7ca-468f-ad91-5f4717fd618b",
   "metadata": {},
   "source": [
    "## Heatmap Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "99811b82-c374-47a6-8ea4-63ed12c49c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_pairwise_ci( \n",
    "        raw_data, \n",
    "        n_iterations=1000,\n",
    "        statistic=np.mean,\n",
    "        units_of_measure=\"jaccard_similarity\"\n",
    "    ):\n",
    "    \n",
    "    data = raw_data.copy()\n",
    "    data[\"question_image\"] = data[\"question\"] + \" & \" + data[\"image_file\"]\n",
    "    rng = Generator(PCG64())\n",
    "    questions = list(data[\"question_image\"].unique())\n",
    "    n_size = len(questions)\n",
    "    df = data.copy()\n",
    "\n",
    "    # sample within the data\n",
    "    df = df.sample(frac=1, replace=True, random_state=1)\n",
    "\n",
    "    def bootstrap_iteration(data, chosen_qs):\n",
    "        filter_df = data[data[\"question_image\"].isin(chosen_qs)] # Filter based on chosen questions\n",
    "        bs_mean = statistic(filter_df[units_of_measure]) # Calculate mean of the filtered data\n",
    "        return bs_mean\n",
    "    means = Parallel(n_jobs=-1)(\n",
    "        delayed(bootstrap_iteration)(df, rng.choice(questions, n_size,  replace=True)) for _ in range(n_iterations)\n",
    "    )\n",
    "    \n",
    "    # 95% confidence interval\n",
    "    lower = np.percentile(means, 2.5)\n",
    "    upper = np.percentile(means, 97.5)\n",
    "    \n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "def create_pairwise_confidence_interval_df(agent_res, units_of_measure=\"jaccard_similarity\", statistic=np.mean):\n",
    "    \n",
    "    lower, upper = bootstrap_pairwise_ci(agent_res, statistic=statistic, units_of_measure=units_of_measure)\n",
    "    stats = {\n",
    "        \"ci_upper\": upper, \n",
    "        \"ci_lower\": lower,\n",
    "        \"mean\": statistic(agent_res[units_of_measure])\n",
    "    }\n",
    "    return stats\n",
    "    # return pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54013f2-844d-44dc-a117-e0aab977dae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/3zpbxkws53b3x6m8509jyml80000gn/T/ipykernel_55311/1395381641.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ggr_csv = pd.read_csv(\"/Users/arnav/Desktop/contextvis/vlm-datavis-benchmark/analysis/tacl_analysis/heatmap/ggr_all_pairwise.csv\", low_memory=True)\n",
      "/var/folders/v8/3zpbxkws53b3x6m8509jyml80000gn/T/ipykernel_55311/1395381641.py:2: DtypeWarning: Columns (4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  vlat_csv = pd.read_csv(\"/Users/arnav/Desktop/contextvis/vlm-datavis-benchmark/analysis/tacl_analysis/heatmap/vlat_all_pairwise.csv\", low_memory=True)\n"
     ]
    }
   ],
   "source": [
    "ggr_csv = pd.read_csv(\"/Users/arnav/Desktop/contextvis/vlm-datavis-benchmark/analysis/tacl_analysis/heatmap/ggr_all_pairwise.csv\", low_memory=True)\n",
    "vlat_csv = pd.read_csv(\"/Users/arnav/Desktop/contextvis/vlm-datavis-benchmark/analysis/tacl_analysis/heatmap/vlat_all_pairwise.csv\", low_memory=True)\n",
    "holf_csv = pd.read_csv(\"/Users/arnav/Desktop/contextvis/vlm-datavis-benchmark/analysis/tacl_analysis/heatmap/holf_all_pairwise.csv\", low_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc292c-a8a5-45c2-b86e-cc2366e93b56",
   "metadata": {},
   "source": [
    "### Between Human / Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91588e03-12cf-496f-94fb-c86c7e86215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vlat_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "f92f74ad-d7ca-44e5-8001-fa26b9801b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def between_human_model_comparison(data, test_type):\n",
    "    agent_map = {\n",
    "        \"llava-hf/llava-1.5-7b-hf\": \"model\",\n",
    "        'Salesforce/blip2-flan-t5-xl': \"model\",\n",
    "        'Salesforce/blip2-flan-t5-xxl': \"model\",\n",
    "        'GPT-4V': \"model\",\n",
    "        'Human/Math-2-1': 'human',\n",
    "        'Human/Math-3': 'human'\n",
    "    }\n",
    "    \n",
    "    df = data.replace(agent_map)\n",
    "    df = df[\n",
    "        (df[\"agentType_A\"] == \"human\") &\n",
    "        (df[\"agentType_B\"] == \"model\")\n",
    "    ]\n",
    "\n",
    "    metric=\"jaccard_similarity\"\n",
    "    if (test_type == \"holf\"):\n",
    "        # df = test_df.groupby([\"agentType_B\", \"agentType_A\"])[metric].median().reset_index()\n",
    "        return create_pairwise_confidence_interval_df(df, statistic=np.median)\n",
    "    else:\n",
    "        return create_pairwise_confidence_interval_df(df)\n",
    "        # df = test_df.replace(agent_map).groupby([\"agentType_B\", \"agentType_A\"])[metric].mean().reset_index()\n",
    "    # return df[(df[\"agentType_A\"] == \"human\") & (df[\"agentType_B\"] == \"model\")][metric].iloc[0]\n",
    "\n",
    "between_human_model_comparison(ggr_csv, \"ggr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b70a3722-8fc0-476d-a0fd-33454e32115c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18405284010842363"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "between_human_model_comparison(ggr_csv, \"ggr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "024f1563-3c0f-4806-9799-7b8a41cb13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ggr_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8026b5d2-209b-4c9c-af44-c0c10ffd3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "between_human_model_comparison(holf_csv, \"holf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ada05b-652a-4fd1-a2fc-2f53f9385229",
   "metadata": {},
   "outputs": [],
   "source": [
    "holf_csv = pd.read_csv(\"/Users/arnav/Desktop/contextvis/vlm-datavis-benchmark/analysis/tacl_analysis/heatmap/holf_all_pairwise.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd52da3c-cfd4-4045-b2f3-72fa7871349e",
   "metadata": {},
   "source": [
    "### Between Humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "22ce684f-45e2-4d99-9133-fc05dfb1a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def between_human_comparison(curr_df, test_type):\n",
    "    agent_map = {\n",
    "        \"llava-hf/llava-1.5-7b-hf\": np.nan,\n",
    "        'Salesforce/blip2-flan-t5-xl': np.nan,\n",
    "        'Salesforce/blip2-flan-t5-xxl': np.nan,\n",
    "        'GPT-4V': np.nan,\n",
    "        'Human/Math-2-1': 'Human/Math-2-1',\n",
    "        'Human/Math-3': 'Human/Math-3'\n",
    "    }\n",
    "    test_df = curr_df.replace(agent_map).dropna(subset=[\"agentType_B\", \"agentType_A\"])\n",
    "\n",
    "    metric=\"jaccard_similarity\"\n",
    "    if (test_type == \"holf\"):\n",
    "        df = test_df.groupby([\"agentType_B\", \"agentType_A\"])[metric].median().reset_index()\n",
    "    else:\n",
    "        df = test_df.groupby([\"agentType_B\", \"agentType_A\"])[metric].mean().reset_index()\n",
    "\n",
    "    return df[(df[\"agentType_A\"] == \"Human/Math-2-1\") & (df[\"agentType_B\"] == \"Human/Math-3\")][metric].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "785f92fd-a1cd-4142-ab2a-2808fd58f310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6828717036231868"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "between_human_comparison(ggr_csv, \"ggr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "2d48217e-39f2-493e-b0d6-281712764da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6804695119137334"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "between_human_comparison(vlat_csv, \"vlat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "39f09540-e48e-4031-9814-c4f1d1429ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0475"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "between_human_comparison(holf_csv, \"holf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e85042d2-c3a3-47d9-8750-2a4e81df6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holf_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6897d0f-641b-470e-81dc-199e0c8c75fe",
   "metadata": {},
   "source": [
    "### Between Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b41a265f-6f96-4066-86ca-8be756c6d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def between_model_comparison(curr_df, test_type):\n",
    "    agent_map = {\n",
    "        \"llava-hf/llava-1.5-7b-hf\": \"model\",\n",
    "        'Salesforce/blip2-flan-t5-xl': \"model\",\n",
    "        'Salesforce/blip2-flan-t5-xxl': \"model\",\n",
    "        'GPT-4V': \"model\",\n",
    "    }\n",
    "    test_df = curr_df.replace(agent_map).dropna(subset=[\"agentType_B\", \"agentType_A\"])\n",
    "\n",
    "    metric=\"jaccard_similarity\"\n",
    "    if (test_type == \"holf\"):\n",
    "        df = test_df.groupby([\"agentType_B\", \"agentType_A\"])[metric].median().reset_index()\n",
    "    else:\n",
    "        df = test_df.groupby([\"agentType_B\", \"agentType_A\"])[metric].mean().reset_index()\n",
    "\n",
    "    return df[(df[\"agentType_A\"] == \"model\") & (df[\"agentType_B\"] == \"model\")][metric].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7c41ad45-b759-4c1c-8479-1b4a1fec0f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2624092888243832"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "between_model_comparison(ggr_csv, \"ggr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "1d6dd59c-bdc2-4ae2-a79f-c996a83ee500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6186843590163636"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "between_model_comparison(vlat_csv, \"vlat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "487a2ee2-5c91-4f7d-bbb9-e3fea3d9dbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "between_model_comparison(holf_csv, \"holf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
